{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "from astropy.io import fits \n",
    "import matplotlib.pyplot as plt \n",
    "import py_specrebin_vec\n",
    "from matplotlib import rc\n",
    "import pandas as pd\n",
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "path_name = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues w/ Mask:A2M33P Slit:181, Mask:B2M33P Slit:139\n",
    "\n",
    "RuntimeError: Optimal parameters not found: Number of calls to function has reached maxfev = 800.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Pannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_name = \"M33D2A\" #Enter your mask here!\n",
    "grating = 600 #Keep the grating 600. BPT doesn't use 1200 grating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wave_600 = np.arange(4000, 11000, .65) \n",
    "new_wave_1200 = np.arange(6000, 11000, .33) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = fits.open(\"./AGST Subtracted Spectra/{}_AGST_Subtracted_Spectra.fits.gz\".format(mask_name))\n",
    "AGST_RBFlux = Data[1].data #Read and extract data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function To Read ISM_EM_LINES.txt & Extract Slit # of Excluded Slits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exclusions():\n",
    "    filepath = 'ISM_EM_LINES.txt'\n",
    "    fp = open(filepath)\n",
    "    all_data = []\n",
    "    for line in (fp):\n",
    "        mask_name = line.split(':')[0].split('_')[0]\n",
    "        slit_number = line.split(':')[1].strip().split(\" \")[0]\n",
    "        if len(slit_number) == 2:\n",
    "            slit_number = '0' + slit_number\n",
    "        elif len(slit_number) == 1:\n",
    "            slit_number = '00' + slit_number\n",
    "        else:\n",
    "            pass\n",
    "        object_id = line.split(':')[1].strip().split()[1]\n",
    "        data = {}\n",
    "        data['mask_name'] = mask_name\n",
    "        data['slit_number'] = slit_number\n",
    "        data['object_id'] = object_id\n",
    "        all_data.append(data)\n",
    "    return all_data     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_to_include(folder):\n",
    "    import os\n",
    "    list_of_files_to_include = []\n",
    "    list_of_files_to_exclude = []\n",
    "    serendip_files = []\n",
    "    all_file_names_in_folder = os.listdir('data/{}'.format(folder))\n",
    "    y = len(all_file_names_in_folder)\n",
    "    print(\"The number of files in the folder is {0}\".format(y))\n",
    "    all_data = get_exclusions()\n",
    "    len_all_data = len(all_data)\n",
    "    for n in range(y):\n",
    "        parts_of_file_name = all_file_names_in_folder[n].split(\".\")\n",
    "        if parts_of_file_name[0] == 'spec1d': # avoids hidden DS_Store files on my mac\n",
    "            object_id = parts_of_file_name[3]\n",
    "            slit_number = parts_of_file_name[2]\n",
    "            mask_name = parts_of_file_name[1]\n",
    "            should_include = True\n",
    "            should_exclude = True\n",
    "            for k in range(len_all_data):\n",
    "                if ((object_id == all_data[k]['object_id']) and (slit_number == all_data[k]['slit_number']) and (mask_name == all_data[k]['mask_name'])):\n",
    "                    should_include = False\n",
    "                    should_exclude = True\n",
    "                if 'serendip' in object_id:\n",
    "                    should_include = False\n",
    "                    should_exclude = False\n",
    "            if should_include == True:\n",
    "                list_of_files_to_include.append(all_file_names_in_folder[n])       \n",
    "            elif should_exclude == True:\n",
    "                list_of_files_to_exclude.append(all_file_names_in_folder[n])\n",
    "            elif should_include == False & should_exclude == False:\n",
    "                serendip_files.append(all_file_names_in_folder[n])\n",
    "    \n",
    "    print('The number of files left after exclusions is {0}'.format(len(list_of_files_to_include)))\n",
    "    \n",
    "    return sorted(list_of_files_to_include), sorted(list_of_files_to_exclude), sorted(serendip_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slit_nums(files):\n",
    "    \n",
    "    slit_nums = []\n",
    "    \n",
    "    if len(files) > 1:\n",
    "    \n",
    "        for i in range(len(files)):\n",
    "            parts_of_file_name = files[i].split(\".\")\n",
    "            slit_num = parts_of_file_name[2]\n",
    "            slit_nums.append(int(slit_num))\n",
    "            \n",
    "    return slit_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calls To Get Slit Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering files\n",
    "list_of_files_to_include, list_of_files_to_exclude, list_of_serendip_files = get_files_to_include(mask_name)\n",
    "\n",
    "file_names = list_of_files_to_include\n",
    "file_names_exclude = list_of_files_to_exclude\n",
    "file_names_serendip = list_of_serendip_files\n",
    "file_names_all = list_of_files_to_include + list_of_files_to_exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slit_nums = get_slit_nums(file_names) #get slit # of INCLUDED slits\n",
    "slit_nums_exclude = get_slit_nums(file_names_exclude) #get slit # of EXCLUDED slits\n",
    "all_slit_nums = get_slit_nums(file_names_all) #slit # of INCLUDED & EXCLUDED slits\n",
    "\n",
    "print(\"Slit # to INCLUDE in median calculation: {0}\".format(slit_nums))\n",
    "print(\"Slit # to EXCLUDE: {0}\".format(slit_nums_exclude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read From Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Slits_For_BPT(mask):\n",
    "    \n",
    "    '''\n",
    "    Return slit number of slits that are used to create BPT diagrams. \n",
    "    \n",
    "    Parameters\n",
    "    ---\n",
    "    mask: str\n",
    "        Name of mask.\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ---\n",
    "    slit_nums: list\n",
    "        List containing slit number of slits in input mask that are used to create BPT diagram. \n",
    "        \n",
    "    '''\n",
    "    \n",
    "    txtfile = open(\"BPT_EM_LINES.txt\",\"r\") #Opening and reading the text file. \n",
    "    lines = txtfile.readlines()\n",
    "\n",
    "    all_mask_names = [] #empty list to add into \n",
    "    all_slit_nums = [] #empty list to add into\n",
    "\n",
    "    for line in lines: \n",
    "        ind_element = line.split(\".\") #Split into three elements.\n",
    "        all_mask_names.append(ind_element[0]) #0th element contains mask name\n",
    "        all_slit_nums.append(ind_element[1]) #1st element contains slit number\n",
    "\n",
    "    slit_nums = np.array(all_slit_nums)[np.array(all_mask_names) == \"{}\".format(mask)] #Create boolean using mask name and use boolean to index.\n",
    "    slit_nums = [int(val) for val in slit_nums] #Convert str -> int.\n",
    "    \n",
    "    if len(slit_nums) == 0:\n",
    "        print(\"No Slits Use in BPT Diagram. Move to Next Mask.\")\n",
    "        raise KeyboardInterrupt(\"No Slits Here! Move to Next Mask!\")\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return slit_nums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SlitNums_of_Mask = Slits_For_BPT(mask_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Integral Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, amplitude, mean, stddev):\n",
    "    return amplitude*np.exp(-((x - mean)**2/(2*(stddev**2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area(window_min,window_max,addons_window_pixels,flux,*args,wave=new_wave_600):\n",
    "    \n",
    "    '''\n",
    "    Calculate the emission line strength of a single emission line. Set first window to \n",
    "    search for emission line within the window. Second window capture data points within first window.\n",
    "    Use captured data to determine Gaussian parameters and performs Gaussian fit. \n",
    "\n",
    "    \n",
    "    Parameters\n",
    "    ---\n",
    "    window_min: int or float\n",
    "        Minimal value of 1st window (search window). \n",
    "    \n",
    "    window_max: int or float\n",
    "        Maximal value of 1st window (search window).\n",
    "    \n",
    "    addons_window_pixels: int\n",
    "        Number of pixels to add onto center of emission line. Width of 2nd window = 2x addons_window_pixels\n",
    "    \n",
    "    flux: ndarry\n",
    "        Flux of one slit.\n",
    "    \n",
    "    *arg: 1.int 2.str\n",
    "        1. Slit number.\n",
    "        2. Name of emission line.\n",
    "    \n",
    "    wave: ndarray\n",
    "        Wavelength of one slit.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ---\n",
    "    Line_STR: int or float\n",
    "        Calculated strength of an emission line.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #1st window (Search window)\n",
    "    WavWin_Bool = (wave > window_min) & (wave < window_max) #Boolean array of wavelength between two set limits\n",
    "    Window_X = wave[WavWin_Bool] #Use boolean array to index x-values of first window\n",
    "    Window_Y = flux[WavWin_Bool] #Use boolean array to index y-values of first window\n",
    "    \n",
    "    #2nd window (Capture window)\n",
    "    Peak_Idx = list(flux).index(max(Window_Y)) #Determine the index of the peak\n",
    "    New_Window_Lim = np.array([Peak_Idx-addons_window_pixels,Peak_Idx+addons_window_pixels]) #Set pixel length of second window\n",
    "    Wavelength = wave[New_Window_Lim[0]:New_Window_Lim[1]] #Wavelength of second window\n",
    "    Flux = flux[New_Window_Lim[0]:New_Window_Lim[1]] #Flux of second window\n",
    "    \n",
    "    #Calculate Amplitude, Mean, and Standard Dev\n",
    "    p0_A = max(Flux) #Guess Amplitude\n",
    "    p0_mu = Wavelength[list(Flux).index(p0_A)] #Guess Mean\n",
    "    p0_sigma = np.std(Wavelength) #Guess Standard Dev\n",
    "    popt,_ = optimize.curve_fit(gaussian,Wavelength,Flux,p0=[p0_A,p0_mu,p0_sigma])\n",
    "    \n",
    "    #Calculate line strength\n",
    "    Amplitude = popt[0]\n",
    "    STD = popt[2]\n",
    "    Line_STR = abs(Amplitude * STD) #Using the Amp*SD/0.3989 formula. Ratio ignore constant.\n",
    "    \n",
    "    #Visual inspection\n",
    "    gaussian_x = np.linspace(wave[New_Window_Lim[0]],wave[New_Window_Lim[1]],100)\n",
    "    gaussian_y = gaussian(gaussian_x,popt[0],popt[1],popt[2])\n",
    "    plt.plot(Window_X,Window_Y,color=\"black\",label=\"First Window\")\n",
    "    plt.plot(Wavelength,Flux,color=\"blue\",label=\"Second Window\")\n",
    "    plt.plot(gaussian_x,gaussian_y,color=\"red\",linestyle=\"--\",label=\"Gaussian\")\n",
    "    plt.vlines(wave[New_Window_Lim[0]],-500,1000,linestyle=\"--\",color=\"green\",label=\"2nd Window Limit\")\n",
    "    plt.vlines(wave[New_Window_Lim[1]],-500,1000,linestyle=\"--\",color=\"green\",label=\"2nd Window Limit\")\n",
    "    plt.xlim(window_min,window_max)\n",
    "    plt.ylim(-30,Amplitude+50)\n",
    "    plt.title(\"Slit Number:{} EM Line:{}\".format(args[0],args[1]))\n",
    "    plt.xlabel(\"Wavelength\")\n",
    "    plt.ylabel(\"Flux (e/hr)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    #Print line strength\n",
    "    print(\"Amplitude: {}\".format(Amplitude))\n",
    "    print(\"Standard Deviation: {}\".format(STD))\n",
    "    print(\"Slit: {} {} Line Strength: {}\".format(args[0],args[1],Line_STR))\n",
    "    \n",
    "    return Line_STR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integral_and_ratios(SlitNums_Use,SlitNums_All,AGST_Sub_Data):\n",
    "    \n",
    "    OIII_Hb_Ratio_List = [] \n",
    "    NII_Ha_Ratio_List = []\n",
    "    Hb_Line_STR_List = []\n",
    "    OIII_Line_STR_List = []\n",
    "    Ha_Line_STR_List = []\n",
    "    NII_Line_STR_List = []\n",
    "    Idx_List = []\n",
    "    \n",
    "    for slit_number in SlitNums_Use:\n",
    "        \n",
    "        Idx_of_Slit = SlitNums_All.index(slit_number) #Extract AGST data\n",
    "        Idx_List.append(Idx_of_Slit)\n",
    "        Data_of_Slit = AGST_Sub_Data[Idx_of_Slit]\n",
    "        \n",
    "        Hb_Line_STR = area(4840,4940,15,Data_of_Slit,slit_number,\"H Beta\") #Calculate the line strength of the H Beta emission line\n",
    "        Hb_Line_STR_List.append(Hb_Line_STR)\n",
    "        \n",
    "        OIII_Line_STR = area(4940,5040,15,Data_of_Slit,slit_number,\"OIII\") #Calculate the line strength of the OIII emission line\n",
    "        OIII_Line_STR_List.append(OIII_Line_STR)\n",
    "        \n",
    "        Ha_Line_STR = area(6540,6570,15,Data_of_Slit,slit_number,\"H Alpha\") #Calculate the line strength of the H Alpha emission line\n",
    "        Ha_Line_STR_List.append(Ha_Line_STR)\n",
    "        \n",
    "        NII_Line_STR = area(6570,6600,15,Data_of_Slit,slit_number,\"NII\") #Calculate the line strength of the NII emission line\n",
    "        NII_Line_STR_List.append(NII_Line_STR)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        OIII_Hb_Ratio = OIII_Line_STR/Hb_Line_STR #Calculate OIII/Hb ratio\n",
    "        OIII_Hb_Ratio_List.append(OIII_Hb_Ratio)\n",
    "        \n",
    "        NII_Ha_Ratio = NII_Line_STR/Ha_Line_STR #Calculate NII/Ha ratio\n",
    "        NII_Ha_Ratio_List.append(NII_Ha_Ratio)\n",
    "        \n",
    "    All_Returned_Data = {\"OIII/Hb Ratio\":OIII_Hb_Ratio_List,\"NII/Ha Ratio\":NII_Ha_Ratio_List,\n",
    "                        \"Hb\":Hb_Line_STR_List,\"OIII\":OIII_Line_STR_List,\"Ha\":Ha_Line_STR_List,\n",
    "                        \"NII\":NII_Line_STR_List}\n",
    "    \n",
    "    return All_Returned_Data,Idx_List\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Returned_Data,Idx_List = integral_and_ratios(SlitNums_of_Mask,slit_nums_exclude,AGST_RBFlux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Returned_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Redshift, QOP, and Create DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def loadMarzResults(filepath):\n",
    "    return numpy.genfromtxt(filepath, delimiter=',', skip_header=2, autostrip=True, names=True, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrays containing all slits processed in MARZ\n",
    "res = loadMarzResults(\"./Marz_Results (Redone)/{0}_Marz_KN.mz\".format(mask_name)) \n",
    "confident = res[res['QOP'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift = [] #empty list for redshift value\n",
    "QOP = [] #empty list for QOP\n",
    "\n",
    "for n in range(len(res)): #sorting \n",
    "    redshift.append(res[n][12])\n",
    "    QOP.append(res[n][13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Redshift to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1= pd.DataFrame({\"Mask Name\":np.full(len(SlitNums_of_Mask),mask_name), #add mask name to DF\n",
    "                   \"Slit Numbers\":np.array(SlitNums_of_Mask),                     \n",
    "                   \"Redshift\":np.array(redshift)[np.array(Idx_List)], #add redshift to DF\n",
    "                   \"QOP\":np.array(QOP)[np.array(Idx_List)]}) #add QOP to DF\n",
    "\n",
    "df_2 = pd.DataFrame(Returned_Data)\n",
    "\n",
    "df = pd.concat([df_1,df_2],axis=1)\n",
    "\n",
    "if os.path.isfile(\"./BPT Diagram CSV/BPT_Ratios_Redo.csv\") == False: #check if file exist. If not make it.\n",
    "    df.to_csv(\"./BPT Diagram CSV/BPT_Ratios_Redo.csv\",index=False) \n",
    "    \n",
    "else: #if file does exist, open and add to it.\n",
    "    redshift_read = pd.read_csv(\"./BPT Diagram CSV/BPT_Ratios_Redo.csv\")\n",
    "    new_csv = pd.concat([redshift_read,df])\n",
    "    new_csv.to_csv(\"./BPT Diagram CSV/BPT_Ratios_Redo.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_DF = pd.read_csv(\"./BPT Diagram CSV/BPT_Ratios_Redo.csv\")\n",
    "Median_of_Ha = np.median(Final_DF[\"Ha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_of_NII_Ha_Ratio = np.log10(Final_DF[\"NII/Ha Ratio\"])\n",
    "Log_of_OIII_Hb_Ratio = np.log10(Final_DF[\"OIII/Hb Ratio\"])\n",
    "plt.scatter(Log_of_NII_Ha_Ratio[Final_DF[\"Ha\"]>Median_of_Ha],Log_of_OIII_Hb_Ratio[Final_DF[\"Ha\"]>Median_of_Ha],label=\"Sorted by Strong Ha\",s=10)\n",
    "plt.scatter(Log_of_NII_Ha_Ratio[Final_DF[\"Ha\"]<Median_of_Ha],Log_of_OIII_Hb_Ratio[Final_DF[\"Ha\"]<Median_of_Ha],label=\"Sorted by Weak Ha\",s=10)\n",
    "plt.xlabel(\"$Log_{10}([NII]/Hα)$\")\n",
    "plt.ylabel(\"$Log_{10}([OIII]/Hβ)$\")\n",
    "plt.title(\"BPT Diagram\")\n",
    "plt.xlim(-1.5,0)\n",
    "plt.ylim(-2.5,1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NII_Ha_Ratio = Final_DF[\"NII/Ha Ratio\"]\n",
    "OIII_Hb_Ratio = Final_DF[\"OIII/Hb Ratio\"]\n",
    "plt.scatter(NII_Ha_Ratio[Final_DF[\"Ha\"]>Median_of_Ha],Log_of_OIII_Hb_Ratio[Final_DF[\"Ha\"]>Median_of_Ha],label=\"Sorted by Strong Ha\",s=10)\n",
    "plt.scatter(NII_Ha_Ratio[Final_DF[\"Ha\"]<Median_of_Ha],Log_of_OIII_Hb_Ratio[Final_DF[\"Ha\"]<Median_of_Ha],label=\"Sorted by Weak Ha\",s=10)\n",
    "plt.xlabel(\"[NII]/Hα\")\n",
    "plt.ylabel(\"[OIII]/Hβ\")\n",
    "plt.title(\"BPT Diagram\")\n",
    "#plt.xlim(-1.5,0)\n",
    "#plt.ylim(-2.5,1)\n",
    "plt.xlim(0.03,3)\n",
    "plt.ylim(0.07,12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Reference Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ref_curve(NII_Ha_RefVal):\n",
    "    return 10**(1.10-(0.6/(0.01-np.log10(NII_Ha_RefVal))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NII_Ha_RefVal = np.arange(0,1,0.01)\n",
    "OIII_Hb_RefVal = ref_curve(NII_Ha_RefVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NII_Ha_Ratio = Final_DF[\"NII/Ha Ratio\"]\n",
    "OIII_Hb_Ratio = Final_DF[\"OIII/Hb Ratio\"]\n",
    "plt.scatter(NII_Ha_Ratio[Final_DF[\"Ha\"]>Median_of_Ha],Log_of_OIII_Hb_Ratio[Final_DF[\"Ha\"]>Median_of_Ha],label=\"Sorted by Strong Ha\",s=10)\n",
    "plt.scatter(NII_Ha_Ratio[Final_DF[\"Ha\"]<Median_of_Ha],Log_of_OIII_Hb_Ratio[Final_DF[\"Ha\"]<Median_of_Ha],label=\"Sorted by Weak Ha\",s=10)\n",
    "plt.plot(NII_Ha_RefVal,OIII_Hb_RefVal,color=\"grey\",linestyle=\"--\")\n",
    "plt.xlabel(\"[NII]/Hα\")\n",
    "plt.ylabel(\"[OIII]/Hβ\")\n",
    "plt.title(\"BPT Diagram\")\n",
    "#plt.xlim(-1.5,0)\n",
    "#plt.ylim(-2.5,1)\n",
    "plt.xlim(0.03,3)\n",
    "plt.ylim(0.07,12)\n",
    "plt.legend()\n",
    "#plt.grid(True)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K03(NII_Ha_RefVal):\n",
    "    return 10**((0.61/(np.log10(NII_Ha_RefVal)-0.05))+1.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NII_Ha_K03 = np.arange(0,1,0.01)\n",
    "OIII_Hb_K03 = K03(NII_Ha_K03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NII_Ha_Ratio = Final_DF[\"NII/Ha Ratio\"]\n",
    "OIII_Hb_Ratio = Final_DF[\"OIII/Hb Ratio\"]\n",
    "plt.scatter(NII_Ha_Ratio[Final_DF[\"Ha\"]>Median_of_Ha],Log_of_OIII_Hb_Ratio[Final_DF[\"Ha\"]>Median_of_Ha],label=\"Sorted by Strong Ha\",s=10)\n",
    "plt.scatter(NII_Ha_Ratio[Final_DF[\"Ha\"]<Median_of_Ha],Log_of_OIII_Hb_Ratio[Final_DF[\"Ha\"]<Median_of_Ha],label=\"Sorted by Weak Ha\",s=10)\n",
    "plt.hlines(3,0.03,3,linewidth=0.5,color=\"grey\")\n",
    "plt.vlines(0.6,0.01,20,linewidth=0.5,color=\"grey\")\n",
    "plt.plot(NII_Ha_RefVal,OIII_Hb_RefVal,color=\"grey\",linestyle=\"--\")\n",
    "plt.plot(NII_Ha_K03,OIII_Hb_K03,color=\"grey\",linestyle=\"--\")\n",
    "plt.xlabel(\"[NII] $\\lambda$6583/Hα\")\n",
    "plt.ylabel(\"[OIII] $\\lambda$5007/Hβ\")\n",
    "plt.title(\"BPT Diagram\")\n",
    "plt.text(1,0.5,\"LINERs\",fontsize=16)\n",
    "plt.text(1,10,\"Seyferts\",fontsize=16)\n",
    "plt.text(0.04,1,\"Star-forming galaxies\",fontsize=12)\n",
    "plt.annotate(\"Reference curve\",xy=(0.2,2),xytext=(0.3,7),arrowprops=dict(facecolor=\"black\",width=1.5,headwidth=7))\n",
    "plt.annotate(\"K03\",xy=(0.3,2),xytext=(0.5,2),arrowprops=dict(facecolor=\"black\",width=1.5,headwidth=7))\n",
    "plt.xlim(0.03,3)\n",
    "plt.ylim(0.01,20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmRatio_VarTemp_OIII_Hb(xi,T_4):\n",
    "        return 214*xi*T_4**(0.494+(0.089*np.log(T_4)))*np.exp(-2.917/T_4)*(10**(8.69-12)/5.37e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmRatio_VarTemp_NII_Ha(xi,T_4):\n",
    "    return 12.4*(1-xi)*T_4**(0.495+(0.04*np.log(T_4)))*np.exp(-2.204/T_4)*(10**(7.83-12)/7.41e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xi = np.arange(0,1.01,0.01)\n",
    "\n",
    "OIII_Hb_7K = EmRatio_VarTemp_OIII_Hb(Xi,0.7)\n",
    "NII_Ha_7K = EmRatio_VarTemp_NII_Ha(Xi,0.7)\n",
    "\n",
    "OIII_Hb_8K = EmRatio_VarTemp_OIII_Hb(Xi,0.8)\n",
    "NII_Ha_8K = EmRatio_VarTemp_NII_Ha(Xi,0.8)\n",
    "\n",
    "OIII_Hb_9K = EmRatio_VarTemp_OIII_Hb(Xi,0.9)\n",
    "NII_Ha_9K = EmRatio_VarTemp_NII_Ha(Xi,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NII_Ha_Ratio = Final_DF[\"NII/Ha Ratio\"]\n",
    "OIII_Hb_Ratio = Final_DF[\"OIII/Hb Ratio\"]\n",
    "plt.scatter(NII_Ha_Ratio[Final_DF[\"Ha\"]>Median_of_Ha],Log_of_OIII_Hb_Ratio[Final_DF[\"Ha\"]>Median_of_Ha],label=\"Sorted by Strong Ha\",s=10)\n",
    "plt.scatter(NII_Ha_Ratio[Final_DF[\"Ha\"]<Median_of_Ha],Log_of_OIII_Hb_Ratio[Final_DF[\"Ha\"]<Median_of_Ha],label=\"Sorted by Weak Ha\",s=10)\n",
    "plt.hlines(3,0.03,3,linewidth=0.5,color=\"black\")\n",
    "plt.vlines(0.6,0.01,20,linewidth=0.5,color=\"black\")\n",
    "plt.plot(NII_Ha_RefVal,OIII_Hb_RefVal,color=\"black\",linestyle=\"--\",linewidth=0.7,dashes=(6,8))\n",
    "plt.plot(NII_Ha_K03,OIII_Hb_K03,color=\"black\",linestyle=\"--\",linewidth=0.7,dashes=(6,8))\n",
    "plt.plot(NII_Ha_7K,OIII_Hb_7K,color='black',linewidth=0.7)\n",
    "plt.text(0.035,7,\"9000 K\",fontsize=12)\n",
    "plt.plot(NII_Ha_8K,OIII_Hb_8K,color='black',linewidth=0.7)\n",
    "plt.text(0.035,4.5,\"8000 K\",fontsize=12)\n",
    "plt.plot(NII_Ha_9K,OIII_Hb_9K,color='black',linewidth=0.7)\n",
    "plt.text(0.035,2.3,\"7000 K\",fontsize=12)\n",
    "plt.xlabel(\"[NII] $\\lambda$6583/Hα\",fontsize=16)\n",
    "plt.ylabel(\"[OIII] $\\lambda$5007/Hβ\",fontsize=16)\n",
    "plt.title(\"BPT Diagram\")\n",
    "plt.text(1,0.5,\"LINERs\",fontsize=16)\n",
    "plt.text(1,4,\"Seyferts\",fontsize=16)\n",
    "plt.text(0.035,1,\"Star-forming galaxies\",fontsize=12)\n",
    "plt.annotate(\"Reference curve\",xy=(0.2,2),xytext=(0.12,10.7),arrowprops=dict(facecolor=\"black\",width=1.5,headwidth=7),fontsize=11)\n",
    "plt.annotate(\"K03\",xy=(0.3,2),xytext=(0.4,6),arrowprops=dict(facecolor=\"black\",width=1.5,headwidth=7),fontsize=11)\n",
    "plt.xlim(0.03,3)\n",
    "plt.ylim(0.06,20)\n",
    "plt.legend(loc=\"upper right\",bbox_to_anchor=(1.2,1))\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.savefig(\"BPT.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_idx = (new_wave_600 > 5735) & (new_wave_600 < 5765)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(new_wave_600[bool_idx],AGST_RBFlux[2][bool_idx])\n",
    "wave_diff = np.diff(new_wave_600[bool_idx])\n",
    "delta_EW = np.sum(abs(wave_diff * AGST_RBFlux[2][bool_idx][0:len(wave_diff)]))\n",
    "delta_EW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear_Func = lambda x,m,b: (m*x)+b\n",
    "Y_Intercept_Func = lambda x,y,m: y-(m*x)\n",
    "X_Value_Func = lambda y,m,b: (y-b)/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_calculation(Wave,AGST_Flux):\n",
    "    \n",
    "    tot_area = 0\n",
    "    plt.figure()\n",
    "    plt.plot(Wave,AGST_Flux)\n",
    "    \n",
    "    for idx in range(len(AGST_Flux)-1):\n",
    "        \n",
    "        if AGST_Flux[idx]>0 and AGST_Flux[idx+1]>0:\n",
    "            m = (AGST_Flux[idx+1]-AGST_Flux[idx])/(Wave[idx+1]-Wave[idx])\n",
    "            b = Y_Intercept_Func(Wave[idx],AGST_Flux[idx],m)\n",
    "            area = integrate.quad(Linear_Func,Wave[idx],Wave[idx+1],args=(m,b))\n",
    "            print(area[0])\n",
    "            plt.fill_between(np.array([Wave[idx],Wave[idx+1]]),np.array([AGST_Flux[idx],AGST_Flux[idx+1]]),0)\n",
    "            tot_area += area[0]\n",
    "            \n",
    "        elif AGST_Flux[idx]>0 and AGST_Flux[idx+1] < 0:\n",
    "            m = (AGST_Flux[idx+1]-AGST_Flux[idx])/(Wave[idx+1]-Wave[idx])\n",
    "            b = Y_Intercept_Func(Wave[idx],AGST_Flux[idx],m)\n",
    "            x_val_at_0 = X_Value_Func(0,m,b)\n",
    "            area = integrate.quad(Linear_Func,Wave[idx],x_val_at_0,args=(m,b))\n",
    "            print(area[0])\n",
    "            plt.fill_between(np.array([Wave[idx],x_val_at_0]),np.array([AGST_Flux[idx],Linear_Func(x_val_at_0,m,b)]),0)\n",
    "            tot_area += area[0]\n",
    "            \n",
    "        elif AGST_Flux[idx]<0 and AGST_Flux[idx+1]>0:\n",
    "            m = (AGST_Flux[idx+1]-AGST_Flux[idx])/(Wave[idx+1]-Wave[idx])\n",
    "            b = Y_Intercept_Func(Wave[idx],AGST_Flux[idx],m)\n",
    "            x_val_at_0 = X_Value_Func(0,m,b)\n",
    "            area = integrate.quad(Linear_Func,x_val_at_0,Wave[idx+1],args=(m,b))\n",
    "            print(area[0])\n",
    "            plt.fill_between(np.array([x_val_at_0,Wave[idx+1]]),np.array([Linear_Func(x_val_at_0,m,b),AGST_Flux[idx+1]]),0)\n",
    "            tot_area += area[0]\n",
    "            \n",
    "        elif AGST_Flux[idx]<0 and AGST_Flux[idx+1]<0:\n",
    "            pass\n",
    "    plt.show()    \n",
    "    return tot_area\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = err_calculation(new_wave_600[bool_idx],AGST_RBFlux[2][bool_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
