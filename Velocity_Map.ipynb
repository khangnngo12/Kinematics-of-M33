{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "import os.path\n",
    "from astropy.coordinates import Angle\n",
    "from astropy import units as u\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**INSTRUCTION**\n",
    "NOTE: This notebook composed of two sections: <br/>\n",
    "    -Extracting RA and DEC, and Redshift <br/>\n",
    "    -Plotting\n",
    "\n",
    "**-Extracting RA and DEC, and Redshift** <br/>\n",
    "1.Create a file titled \"Redshift CSV\" in the same workspace as this notebook. Your CSV file contining the RA, Dec, Redshift, and QOP will be stored here.<br/>\n",
    "2.Below the \"Saving DataFrame as CSV File\" is the #BREAK. Run everything from there and above. <br/>\n",
    "3.This will find the RA, Dec, Redshift, and QOP -> Find if there an existing CSV file to save them  -> If no, create the appropriate file to save it -> If yes, open it and add to it. <br/>\n",
    "4.Change mask_name to a new file and run for all mask. <br/>\n",
    "\n",
    "**-Plotting** <br/>\n",
    "1.\"Plotting\" and \"Using Delta_RA and Delta_Dec\" sections will produce your velocity map. Run these two sections after you have run all masks through the previous section. <br/>\n",
    "2.Four plots will be produced. Two maps will be your velocity maps with Dec and RA. Two maps will be your velocity maps with Delta Dec and Delta RA. \n",
    "\n",
    "**-HI and CO Maps** <br/>\n",
    "1.Required M33_2018b_phot_spec.txt to run <br/>\n",
    "2.Run section to extract data, convert to deg, and plot. <br/>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Pannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_name = \"E2M33R\" #Input mask name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Excluded and Includes Slit Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exclusions():\n",
    "    filepath = 'ISM_EM_LINES.txt'\n",
    "    fp = open(filepath)\n",
    "    all_data = []\n",
    "    for line in (fp):\n",
    "        mask_name = line.split(':')[0].split('_')[0]\n",
    "        slit_number = line.split(':')[1].strip().split(\" \")[0]\n",
    "        if len(slit_number) == 2:\n",
    "            slit_number = '0' + slit_number\n",
    "        elif len(slit_number) == 1:\n",
    "            slit_number = '00' + slit_number\n",
    "        else:\n",
    "            pass\n",
    "        object_id = line.split(':')[1].strip().split()[1]\n",
    "        data = {}\n",
    "        data['mask_name'] = mask_name\n",
    "        data['slit_number'] = slit_number\n",
    "        data['object_id'] = object_id\n",
    "        all_data.append(data)\n",
    "    return all_data     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_to_include(folder):\n",
    "    import os\n",
    "    list_of_files_to_include = []\n",
    "    list_of_files_to_exclude = []\n",
    "    serendip_files = []\n",
    "    all_file_names_in_folder = os.listdir('data/{}'.format(folder))\n",
    "    y = len(all_file_names_in_folder)\n",
    "    print(\"The number of files in the folder is {0}\".format(y))\n",
    "    all_data = get_exclusions()\n",
    "    len_all_data = len(all_data)\n",
    "    for n in range(y):\n",
    "        parts_of_file_name = all_file_names_in_folder[n].split(\".\")\n",
    "        if parts_of_file_name[0] == 'spec1d': # avoids hidden DS_Store files on my mac\n",
    "            object_id = parts_of_file_name[3]\n",
    "            slit_number = parts_of_file_name[2]\n",
    "            mask_name = parts_of_file_name[1]\n",
    "            should_include = True\n",
    "            should_exclude = True\n",
    "            for k in range(len_all_data):\n",
    "                if ((object_id == all_data[k]['object_id']) and (slit_number == all_data[k]['slit_number']) and (mask_name == all_data[k]['mask_name'])):\n",
    "                    should_include = False\n",
    "                    should_exclude = True\n",
    "                if 'serendip' in object_id:\n",
    "                    should_include = False\n",
    "                    should_exclude = False\n",
    "            if should_include == True:\n",
    "                list_of_files_to_include.append(all_file_names_in_folder[n])       \n",
    "            elif should_exclude == True:\n",
    "                list_of_files_to_exclude.append(all_file_names_in_folder[n])\n",
    "            elif should_include == False & should_exclude == False:\n",
    "                serendip_files.append(all_file_names_in_folder[n])\n",
    "    \n",
    "    print('The number of files left after exclusions is {0}'.format(len(list_of_files_to_include)))\n",
    "    \n",
    "    return sorted(list_of_files_to_include), sorted(list_of_files_to_exclude), sorted(serendip_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slit_nums(files):\n",
    "    \n",
    "    slit_nums = []\n",
    "    \n",
    "    if len(files) > 1:\n",
    "    \n",
    "        for i in range(len(files)):\n",
    "            parts_of_file_name = files[i].split(\".\")\n",
    "            slit_num = parts_of_file_name[2]\n",
    "            slit_nums.append(int(slit_num))\n",
    "            \n",
    "    return slit_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering files\n",
    "list_of_files_to_include, list_of_files_to_exclude, list_of_serendip_files = get_files_to_include(mask_name)\n",
    "\n",
    "file_names = list_of_files_to_include #included\n",
    "file_names_exclude = list_of_files_to_exclude #excluded\n",
    "file_names_serendip = list_of_serendip_files #serendips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slit_nums = get_slit_nums(file_names)\n",
    "slit_nums_exclude = get_slit_nums(file_names_exclude)\n",
    "\n",
    "print(\"Slit # to INCLUDE in median calculation: {0}\".format(slit_nums))\n",
    "print(\"Slit # to EXCLUDE: {0}\".format(slit_nums_exclude))\n",
    "print(\"Len of EXCL Slits: {0}\".format(len(slit_nums_exclude)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read RA, DEC, and Object ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sky_coor(mask_name,list_of_excl_files,slit_nums_exclude):\n",
    "    \n",
    "    ra = [] #in deg\n",
    "    dec = [] #in deg\n",
    "    object_id = [] #object id\n",
    "    \n",
    "    for file in list_of_excl_files:\n",
    "        #extracting RA and DEC from data files\n",
    "        open_fits = fits.open(\"./data/{0}/{1}\".format(mask_name,file))\n",
    "        ra_obj = open_fits[1].header[\"RA_OBJ\"].split(\":\") #[Hour,Min,Sec]\n",
    "        dec_obj = open_fits[1].header[\"DEC_OBJ\"].strip(\"+\").split(\":\") #[Deg,Min,Sec]\n",
    "        \n",
    "        try: #save OBJID as int. If OBJID has letter, save as str\n",
    "            obj_id = int(open_fits[1].header[\"OBJNO\"])\n",
    "        except:\n",
    "            obj_id = open_fits[1].header[\"OBJNO\"]\n",
    "        \n",
    "        #converting RA (HMS) to degrees format\n",
    "        ra_obj_deg = (float(ra_obj[0]) + (float(ra_obj[1])/60) + (float(ra_obj[2])/3600)) * 15\n",
    "        ra.append(ra_obj_deg)\n",
    "        \n",
    "        #converting Dec (DMS) to degrees format\n",
    "        dec_obj_deg = (float(dec_obj[0]) + (float(dec_obj[1])/60) + (float(dec_obj[2])/3600))\n",
    "        dec.append(dec_obj_deg)\n",
    "    \n",
    "        #add Object ID to list\n",
    "        object_id.append(obj_id)\n",
    "        \n",
    "    #create DataFrame\n",
    "    df = pd.DataFrame({\"Mask Name\":np.full(len(ra),mask_name),\"Slit Number\":slit_nums_exclude,\n",
    "                       \"RA\":ra,\"DEC\":dec,\"OBJECT ID\":object_id})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_sky_coor(mask_name,file_names_exclude,slit_nums_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def loadMarzResults(filepath):\n",
    "    return numpy.genfromtxt(filepath, delimiter=',', skip_header=2, autostrip=True, names=True, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrays containing all slits processed in MARZ\n",
    "res = loadMarzResults(\"./Marz_Results (Redone)/{0}_Marz_KN.mz\".format(mask_name)) \n",
    "confident = res[res['QOP'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift = {} #empty dict for redshift value\n",
    "QOP = {} #empty dict for QOP\n",
    "\n",
    "for n in range(len(res)): #sorting \n",
    "    redshift[\"Slit_{0}\".format(slit_nums_exclude[n])] = res[n][12]*300000 #km/s\n",
    "    QOP[\"Slit_{0}\".format(slit_nums_exclude[n])] = res[n][13]\n",
    "\n",
    "df[\"Velocity (km/s)\"] = redshift.values() #adding column titled \"Velocity\" into DF\n",
    "df[\"QOP\"] = QOP.values() #adding column titled \"QOP\" into DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving DataFrame as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savingdf_csv(df):\n",
    "    if os.path.isfile(\"./Redshift CSV/Redshift.csv\") == False: #isfile check if a file exist\n",
    "        df.to_csv(\"./Redshift CSV/Redshift.csv\",index=False)\n",
    "    else:\n",
    "        csv_to_df = pd.read_csv(\"./Redshift CSV/Redshift.csv\")\n",
    "        new_df = pd.concat([csv_to_df,df]) #concat add two DF together \n",
    "        new_df.to_csv(\"./Redshift CSV/Redshift.csv\",index=False) #put index_column = False so that \n",
    "        #the overwritten csv file don't have extra column called \"unnamed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savingdf_csv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BREAK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./Redshift CSV/Redshift.csv\")\n",
    "df1_qop2_sorted = df1[\"QOP\"] >= 2 #use only values that has a QOP of >= 2\n",
    "df1_qop3_sorted = df1[\"QOP\"] == 3 #use only values that has a QOP of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "ax.set_xlabel(\"Right Ascension (deg)\")\n",
    "ax.set_ylabel(\"Declination (deg)\")\n",
    "ax.set_title(\"M33 Velocity Color Map (QOP >= 2)\")\n",
    "ax.set_xlim(23.2,23.8)\n",
    "ax.set_ylim(30.15,30.9)\n",
    "ax.invert_xaxis()\n",
    "ax.set_aspect(1/0.861)\n",
    "cc_map = ax.scatter(df1[\"RA\"][df1_qop2_sorted]\n",
    "                    ,df1[\"DEC\"][df1_qop2_sorted]\n",
    "                    ,c=df1[\"Redshift\"][df1_qop2_sorted],s=7,cmap='magma')\n",
    "plt.colorbar(cc_map,label=\"Velocity (km/s)\")\n",
    "fig.set_figwidth(5)\n",
    "fig.set_figheight(5)\n",
    "plt.savefig(\"Velocity Map (QOP >= 2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "ax.set_xlabel(\"Right Ascension (deg)\")\n",
    "ax.set_ylabel(\"Declination (deg)\")\n",
    "ax.set_title(\"M33 Velocity Color Map (QOP == 3)\")\n",
    "ax.set_aspect(1/0.861)\n",
    "ax.set_xlim(23.2,23.8)\n",
    "ax.set_ylim(30.15,30.9)\n",
    "ax.invert_xaxis()\n",
    "cc_map = ax.scatter(df1[\"RA\"][df1_qop3_sorted]\n",
    "                    ,df1[\"DEC\"][df1_qop3_sorted]\n",
    "                    ,c=df1[\"Redshift\"][df1_qop3_sorted],s=7,cmap='magma')\n",
    "plt.colorbar(cc_map,label=\"Velocity (km/s)\")\n",
    "fig.set_figwidth(5)\n",
    "fig.set_figheight(5)\n",
    "plt.savefig(\"Velocity Map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Delta_RA and Delta_Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ra_m32 = 01:33:50.8966\n",
    "#dec_m32 = +30:39:36.630\n",
    "ra_m32 = (1 + (33/60) + (50.8966/3600))*15 #in deg\n",
    "dec_m32 = (30 + (39/60) + (36.630/3600)) # in deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "ax.set_xlabel(\"Delta RA (deg)\")\n",
    "ax.set_ylabel(\"Delta Dec (deg)\")\n",
    "ax.set_title(\"M33 Velocity Color Map (QOP >= 2)\")\n",
    "ax.invert_xaxis()\n",
    "ax.set_aspect(\"equal\")\n",
    "cc_map = ax.scatter(((df1[\"RA\"][df1_qop2_sorted]-ra_m32)*np.cos(dec_m32))\n",
    "                    ,(df1[\"DEC\"][df1_qop2_sorted]-dec_m32)\n",
    "                    ,c=df1[\"Redshift\"][df1_qop2_sorted],s=7,cmap='magma')\n",
    "plt.colorbar(cc_map,label=\"Velocity (km/s)\")\n",
    "fig.set_figwidth(5)\n",
    "fig.set_figheight(5)\n",
    "plt.savefig(\"Velocity Map (QOP >= 2) w Del RA and Dec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "ax.set_xlabel(\"Delta RA (deg)\")\n",
    "ax.set_ylabel(\"Delta Dec (deg)\")\n",
    "ax.set_title(\"M33 Velocity Color Map (QOP == 3)\")\n",
    "ax.invert_xaxis()\n",
    "ax.set_aspect(\"equal\")\n",
    "cc_map = ax.scatter(((df1[\"RA\"][df1_qop3_sorted]-ra_m32)*np.cos(dec_m32))\n",
    "                    ,(df1[\"DEC\"][df1_qop3_sorted]-dec_m32)\n",
    "                    ,c=df1[\"Redshift\"][df1_qop3_sorted],s=7,cmap='magma')\n",
    "plt.colorbar(cc_map,label=\"Velocity (km/s)\")\n",
    "fig.set_figwidth(5)\n",
    "fig.set_figheight(5)\n",
    "plt.savefig(\"Velocity Map w Del RA and Dec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BREAK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HI and CO Maps and Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_M33_phot_spec():\n",
    "    \n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    RA: 1d-array containing RA in unit of deg.\n",
    "    Dec: 1d-array containing Dec in unit of deg.\n",
    "    maskname: list containing name of mask in M33_2018b_phot_spec.txt\n",
    "    HI: 1d-array containing velocity measurements in HI region.\n",
    "    CO: 1d-array containing velocity measurements in CO region.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    RA = [] #Empty list to append RA\n",
    "    Dec = [] #Empty list to append Dec\n",
    "    maskname = [] #Empty list to append mask name\n",
    "    HI = [] #Empty list to append v of HI region\n",
    "    CO = [] #Empty list to append v of CO region\n",
    "    OBJID = []\n",
    "    \n",
    "    M33_phot_spec_lines = open(\"M33_2018b_phot_spec.txt\",\"r\").readlines()\n",
    "    for line in M33_phot_spec_lines[1:]: #[1:0] so that it does NOT read the labels\n",
    "        RA.append(Angle(line.split()[1],u.hourangle).degree) #converting RA to Deg\n",
    "        Dec.append(Angle(line.split()[2],u.deg).degree) #converting Dec to Deg\n",
    "        maskname.append(line.split()[16]) #mask name of current line\n",
    "        HI.append(float(line.split()[19])) #HI measurement of current line\n",
    "        CO.append(float(line.split()[20])) #CO measurement of current line\n",
    "        OBJID.append(line.split()[0]) #OBJID \n",
    "        \n",
    "    return np.array(RA),np.array(Dec),maskname,np.array(HI),np.array(CO),OBJID\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ri_As,Decli,Maskname,HI,CO,OBJID = read_M33_phot_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HI_index = np.isnan(HI)==False #remove nan values from HI\n",
    "CO_index = np.isnan(CO)==False #remove nan values from CO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting HI and CO Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "ax.set_xlabel(\"Right Ascension (deg)\")\n",
    "ax.set_ylabel(\"Declination (deg)\")\n",
    "ax.set_title(\"HI Region\")\n",
    "ax.set_xlim(23.2,23.8)\n",
    "ax.set_ylim(30.15,30.9)\n",
    "ax.invert_xaxis()\n",
    "ax.set_aspect(1/0.861)\n",
    "cc_map = ax.scatter(Ri_As[HI_index],Decli[HI_index],c=HI[HI_index],s=7,cmap='magma')\n",
    "plt.colorbar(cc_map,label=\"Velocity (km/s)\")\n",
    "fig.set_figwidth(5)\n",
    "fig.set_figheight(5)\n",
    "plt.savefig(\"HI Region\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "ax.set_xlabel(\"Right Ascension (deg)\")\n",
    "ax.set_ylabel(\"Declination (deg)\")\n",
    "ax.set_title(\"CO Region\")\n",
    "ax.set_xlim(23.2,23.8)\n",
    "ax.set_ylim(30.15,30.9)\n",
    "ax.invert_xaxis()\n",
    "ax.set_aspect(1/0.861)\n",
    "cc_map = ax.scatter(Ri_As[CO_index],Decli[CO_index],c=CO[CO_index],s=7,cmap='magma')\n",
    "plt.colorbar(cc_map,label=\"Velocity (km/s)\")\n",
    "fig.set_figwidth(5)\n",
    "fig.set_figheight(5)\n",
    "plt.savefig(\"CO Region\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine # of Shared OBJ and Make Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_obj(Maskname,OBJID):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    Maskname: list, req\n",
    "        List containing mask names of all mask in M33_2018b_phot_spec.txt\n",
    "    OBJID: list, req\n",
    "        List containing Object ID of all objects in M33_2018b_phot_spec.txt\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Bool: List containing booleans of Redshift.csv objects in M33_2018b_phot_spec.txt\n",
    "    Bool_Index: List containing indices of True values in Bool.\n",
    "    csv_data: DataFrame containing content in Redshift.csv\n",
    "    \"\"\"\n",
    "    csv_data = pd.read_csv(\"./Redshift CSV/Redshift.csv\") #Read Redshift.csv and extract the Mask Namd and OBJID columns\n",
    "    OBJID_myData = csv_data[\"OBJECT ID\"]\n",
    "    Maskname_myData = csv_data[\"Mask Name\"]\n",
    "    TupPairs_myData = list(zip(Maskname_myData,OBJID_myData)) #Create pairs of data\n",
    "    TupPairs = list(zip(Maskname,OBJID)) #Create pairs of data from M33_2018b_phot_spec.txt\n",
    "    Bool = [pair in TupPairs for pair in TupPairs_myData] #List of Bool checking whether objects in Redshift.csv is in M33_2018b_phot_spec.txt\n",
    "    Bool_Index = [TupPairs.index(TupPairs_myData[index]) for index in range(len(Bool)) if Bool[index] == True]\n",
    "    #Reverse_Bool = [pair in TupPairs_myData for pair in TupPairs] #List of Bool checking whether objects in M33_2018b_phot_spec.txt is in Redshift.csv\n",
    "    \n",
    "    return Bool,Bool_Index,csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bool,Bool_Index,csv_data = shared_obj(Maskname,OBJID)\n",
    "myDataDF = pd.DataFrame({\"Mask Name\":csv_data[\"Mask Name\"][np.where(np.array(Bool)==True)[0]],\n",
    "                        \"OBJID\":csv_data[\"OBJECT ID\"][np.where(np.array(Bool)==True)[0]],\n",
    "                        \"Velocity (km/s)\":csv_data[\"Velocity (km/s)\"][np.where(np.array(Bool)==True)[0]],\n",
    "                        \"Mask Name(Check)\":np.array(Maskname)[np.array(Bool_Index)],\n",
    "                        \"OBJID(Check)\":np.array(OBJID)[np.array(Bool_Index)],\n",
    "                        \"HI\":HI[np.array(Bool_Index)],\n",
    "                        \"CO\":CO[np.array(Bool_Index)],\n",
    "                        \"RA\":Ri_As[np.array(Bool_Index)],\n",
    "                        \"Dec\":Decli[np.array(Bool_Index)]}) #DF to stores relevant info\n",
    " \n",
    "myDataDF.to_csv(\"./Redshift CSV/Redshift (incl. CO and HI).csv\",index=False)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Histograms of HAlpha-HI, HAlpha-CO, and HI-CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.array(myDataDF[\"Velocity (km/s)\"]) #velocity calculated by me\n",
    "HI_V = np.array(myDataDF[\"HI\"]) #HI velocity from Amanda's data\n",
    "CO_V = np.array(myDataDF[\"CO\"]) #CO velocity from Amanda's data\n",
    "VsubHI = V - HI_V #Halpha - HI\n",
    "VsubCO = V - CO_V #Halpha - CO\n",
    "HIsubCO = HI_V - CO_V #HI - CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_distribution(x,mu,sigma):\n",
    "    return (1/(np.sqrt(2*np.pi)*sigma))*np.exp((-1/(2*(sigma**2)))*((x-mu)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-250,250,1000)\n",
    "mu, sigma = norm.fit(VsubHI[~np.isnan(VsubHI)]) #estimate mean and standard dev\n",
    "f_x = normal_distribution(x,mu,sigma) #normal distribution formula\n",
    "#p = norm.pdf(filler_data,mu,std)\n",
    "Hist_info = plt.hist(VsubHI[~np.isnan(VsubHI)],bins=50,density=True,label=\"Distribution\")\n",
    "plt.plot(x,f_x,label=\"Gaussian Curve\")\n",
    "plt.title(\"$\\mu$={0},$\\sigma$={1}\".format(round(mu,2),round(sigma,2)))\n",
    "plt.xlabel(\"H-Alpha Velocity - HI Velocity\")\n",
    "plt.xlim(-100,100)\n",
    "plt.legend()\n",
    "plt.savefig(\"HAlpha-HI Histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1, sigma1 = norm.fit(VsubCO[~np.isnan(VsubCO)])\n",
    "f_x1 = normal_distribution(x,mu1,sigma1) #normal distribution formula\n",
    "#p1 = norm.pdf(filler_data,mu1,std1)\n",
    "Hist_info_1 = plt.hist(VsubCO[~np.isnan(VsubCO)],bins=50,density=True,label=\"Distribution\")\n",
    "plt.plot(x,f_x1,label=\"Gaussian Curve\")\n",
    "plt.title(\"$\\mu$={0},$\\sigma$={1}\".format(round(mu1,2),round(sigma1,2)))\n",
    "plt.xlabel(\"H-Alpha Velocity - CO Velocity\")\n",
    "plt.xlim(-100,100)\n",
    "plt.legend()\n",
    "plt.savefig(\"HAlpha-CO Histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu2, sigma2 = norm.fit(HIsubCO[~np.isnan(HIsubCO)])\n",
    "f_x2 = normal_distribution(x,mu2,sigma2) #normal distribution formula\n",
    "#p1 = norm.pdf(filler_data,mu1,std1)\n",
    "Hist_info_2 = plt.hist(HIsubCO[~np.isnan(HIsubCO)],bins=50,range=(-50,50),density=True,label=\"Distribution\")\n",
    "plt.plot(x,f_x2,label=\"Gaussian Curve\")\n",
    "plt.title(\"$\\mu$={0},$\\sigma$={1}\".format(round(mu2,2),round(sigma2,2)))\n",
    "plt.xlabel(\"HI Velocity - CO Velocity\")\n",
    "plt.xlim(-100,100)\n",
    "plt.legend()\n",
    "plt.savefig(\"HI-CO Histogram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CC Map Using Subtraction Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "ax.set_xlabel(\"Right Ascension (deg)\")\n",
    "ax.set_ylabel(\"Declination (deg)\")\n",
    "ax.set_title(\"H-Alpha Velocity - HI Velocity\")\n",
    "ax.set_xlim(23.2,23.8)\n",
    "ax.set_ylim(30.15,30.9)\n",
    "ax.invert_xaxis()\n",
    "ax.set_aspect(1/0.861)\n",
    "cc_map = ax.scatter(myDataDF[\"RA\"][~np.isnan(VsubHI)]\n",
    "                    ,myDataDF[\"Dec\"][~np.isnan(VsubHI)]\n",
    "                    ,c=VsubHI[~np.isnan(VsubHI)],s=7,cmap='magma')\n",
    "plt.colorbar(cc_map,label=\"Velocity (km/s)\")\n",
    "fig.set_figwidth(5)\n",
    "fig.set_figheight(5)\n",
    "plt.savefig(\"H-Alpha - HI.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "ax.set_xlabel(\"Right Ascension (deg)\")\n",
    "ax.set_ylabel(\"Declination (deg)\")\n",
    "ax.set_title(\"H-Alpha Velocity - CO Velocity\")\n",
    "ax.set_xlim(23.2,23.8)\n",
    "ax.set_ylim(30.15,30.9)\n",
    "ax.invert_xaxis()\n",
    "ax.set_aspect(1/0.861)\n",
    "cc_map = ax.scatter(myDataDF[\"RA\"][~np.isnan(VsubCO)]\n",
    "                    ,myDataDF[\"Dec\"][~np.isnan(VsubCO)]\n",
    "                    ,c=VsubCO[~np.isnan(VsubCO)],s=7,cmap='magma')\n",
    "plt.colorbar(cc_map,label=\"Velocity (km/s)\")\n",
    "fig.set_figwidth(5)\n",
    "fig.set_figheight(5)\n",
    "plt.savefig(\"H-Alpha - CO.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "ax.set_xlabel(\"Right Ascension (deg)\")\n",
    "ax.set_ylabel(\"Declination (deg)\")\n",
    "ax.set_title(\"HI Velocity - CO Velocity\")\n",
    "ax.set_xlim(23.2,23.8)\n",
    "ax.set_ylim(30.15,30.9)\n",
    "ax.invert_xaxis()\n",
    "ax.set_aspect(1/0.861)\n",
    "cc_map = ax.scatter(myDataDF[\"RA\"][~np.isnan(HIsubCO)]\n",
    "                    ,myDataDF[\"Dec\"][~np.isnan(HIsubCO)]\n",
    "                    ,c=HIsubCO[~np.isnan(HIsubCO)],s=7,cmap='magma')\n",
    "plt.colorbar(cc_map,label=\"Velocity (km/s)\")\n",
    "fig.set_figwidth(5)\n",
    "fig.set_figheight(5)\n",
    "plt.savefig(\"HI - CO.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
