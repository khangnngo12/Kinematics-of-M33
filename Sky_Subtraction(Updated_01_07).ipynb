{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Defining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRATING = 600ZD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "from astropy.io import fits \n",
    "from smooth_kevin import smoother\n",
    "import py_specrebin\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import rc\n",
    "import py_specrebin\n",
    "path_name = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caution: Execute the following cell only once per run. Do not modify the ```std_out``` or ```std_err``` variables. If they are modified by accident, please restart the kernel and run the notebook from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the original streams for stdout and stderr. To be used for logging output later\n",
    "import sys\n",
    "std_out = sys.stdout; std_err = sys.stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wave_600 = np.arange(4000, 11000, .65) \n",
    "new_wave_1200 = np.arange(6000, 11000, .33) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_data(file_names,mask_name):\n",
    "    \n",
    "    tot_flux = []\n",
    "    tot_wave = []\n",
    "    tot_ivar = []\n",
    "    \n",
    "    for j in range(len(file_names)):\n",
    "        #read in star data\n",
    "        h_star = fits.open(path_name + '/' + 'data/{0}'.format(mask_name) + '/' + file_names[j], ignore_missing_end = True)\n",
    "        \n",
    "        data_star1 = h_star[1].data\n",
    "        star_flux1 = data_star1['SKYSPEC'][0]\n",
    "        star_wave1 = data_star1['LAMBDA'][0]\n",
    "        star_ivar1 = data_star1['IVAR'][0]\n",
    "        \n",
    "        data_star2 = h_star[2].data\n",
    "        star_flux2 = data_star2['SKYSPEC'][0]\n",
    "        star_wave2 = data_star2['LAMBDA'][0]\n",
    "        star_ivar2 = data_star2['IVAR'][0]\n",
    "        \n",
    "        \n",
    "        #combine the blue and red side into one list\n",
    "        star_flux = np.array(list(star_flux1) + list(star_flux2))\n",
    "        star_wave = np.array(list(star_wave1) + list(star_wave2))\n",
    "        star_ivar = np.array(list(star_ivar1) + list(star_ivar2))\n",
    "        \n",
    "        if (sum(star_flux) == 0 and sum(star_ivar) == 0 and sum(star_wave) == 0):\n",
    "            file_name_split = file_names[j].split(\".\")\n",
    "            serendip_file_name = \"{0}.{1}.{2}.serendip1.{3}.{4}\".format(file_name_split[0],file_name_split[1],\n",
    "                                                                   file_name_split[2],file_name_split[4],file_name_split[5])\n",
    "            path_to_serendip = fits.open(path_name + '/' + \"data/{0}/{1}\".format(mask_name,serendip_file_name))\n",
    "            \n",
    "            star_flux1_serendip = path_to_serendip[1].data[\"SKYSPEC\"][0]\n",
    "            star_flux2_serendip = path_to_serendip[2].data[\"SKYSPEC\"][0]\n",
    "            star_flux_serendip = np.concatenate((star_flux1_serendip,star_flux2_serendip))\n",
    "            \n",
    "            star_ivar1_serendip = path_to_serendip[1].data[\"IVAR\"][0]\n",
    "            star_ivar2_serendip = path_to_serendip[2].data[\"IVAR\"][0]\n",
    "            star_ivar_serendip = np.concatenate((star_ivar1_serendip,star_ivar2_serendip))\n",
    "            \n",
    "            star_wave1_serendip = path_to_serendip[1].data[\"LAMBDA\"][0]\n",
    "            star_wave2_serendip = path_to_serendip[2].data[\"LAMBDA\"][0]\n",
    "            star_wave_serendip = np.concatenate((star_wave1_serendip,star_wave2_serendip))\n",
    "            \n",
    "            tot_flux.append(star_flux_serendip)\n",
    "            tot_wave.append(star_wave_serendip)\n",
    "            tot_ivar.append(star_ivar_serendip)\n",
    "            \n",
    "            h_star.close()\n",
    "        \n",
    "        else:\n",
    "            #add to above lists\n",
    "            tot_flux.append(star_flux)\n",
    "            tot_wave.append(star_wave)\n",
    "            tot_ivar.append(star_ivar)\n",
    "\n",
    "            h_star.close()\n",
    "        \n",
    "    return tot_flux, tot_wave, tot_ivar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebin(fluxes, waves, ivar, grating):\n",
    "    \n",
    "    rbflux = []\n",
    "    rbivar = []\n",
    "    \n",
    "    if grating == 600:\n",
    "        new_wave = new_wave_600\n",
    "    elif grating == 1200:\n",
    "        new_wave = new_wave_1200\n",
    "    \n",
    "    for i in range(len(waves)):\n",
    "        new_flux,new_ivar = py_specrebin.rebinspec(waves[i],fluxes[i],new_wave,ivar=ivar[i])\n",
    "        new_flux_err = 1/np.sqrt(new_ivar)\n",
    "\n",
    "        rbflux.append(new_flux)\n",
    "        rbivar.append(new_ivar)\n",
    "        \n",
    "    return rbflux, new_wave, rbivar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_median(rebinned_flux_array):\n",
    "    \n",
    "    median_vals = []\n",
    "    \n",
    "    print(len(rebinned_flux_array))\n",
    "    \n",
    "    for i in range(len(rebinned_flux_array[0])):\n",
    "\n",
    "        comp = []\n",
    "        \n",
    "        for array in rebinned_flux_array:\n",
    "            \n",
    "            if np.isfinite(array[i]) == True:\n",
    "                comp.append(array[i])\n",
    "                \n",
    "        median_vals.append(np.median(comp))\n",
    "        \n",
    "    return median_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exclusions():\n",
    "    filepath = 'ISM_EM_LINES.txt'\n",
    "    fp = open(filepath)\n",
    "    all_data = []\n",
    "    for line in (fp):\n",
    "        mask_name = line.split(':')[0].split('_')[0]\n",
    "        slit_number = line.split(':')[1].strip().split(\" \")[0]\n",
    "        if len(slit_number) == 2:\n",
    "            slit_number = '0' + slit_number\n",
    "        elif len(slit_number) == 1:\n",
    "            slit_number = '00' + slit_number\n",
    "        else:\n",
    "            pass\n",
    "        object_id = line.split(':')[1].strip().split()[1]\n",
    "        data = {}\n",
    "        data['mask_name'] = mask_name\n",
    "        data['slit_number'] = slit_number\n",
    "        data['object_id'] = object_id\n",
    "        all_data.append(data)\n",
    "    return all_data     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_to_include(folder):\n",
    "    import os\n",
    "    list_of_files_to_include = []\n",
    "    list_of_files_to_exclude = []\n",
    "    serendip_files = []\n",
    "    all_file_names_in_folder = os.listdir('data/{}'.format(folder))\n",
    "    y = len(all_file_names_in_folder)\n",
    "    print(\"The number of files in the folder is {0}\".format(y))\n",
    "    all_data = get_exclusions()\n",
    "    len_all_data = len(all_data)\n",
    "    for n in range(y):\n",
    "        parts_of_file_name = all_file_names_in_folder[n].split(\".\")\n",
    "        if parts_of_file_name[0] == 'spec1d': # avoids hidden DS_Store files on my mac\n",
    "            object_id = parts_of_file_name[3]\n",
    "            slit_number = parts_of_file_name[2]\n",
    "            mask_name = parts_of_file_name[1]\n",
    "            should_include = True\n",
    "            should_exclude = True\n",
    "            for k in range(len_all_data):\n",
    "                if ((object_id == all_data[k]['object_id']) and (slit_number == all_data[k]['slit_number']) and (mask_name == all_data[k]['mask_name'])):\n",
    "                    should_include = False\n",
    "                    should_exclude = True\n",
    "                if 'serendip' in object_id:\n",
    "                    should_include = False\n",
    "                    should_exclude = False\n",
    "            if should_include == True:\n",
    "                list_of_files_to_include.append(all_file_names_in_folder[n])       \n",
    "            elif should_exclude == True:\n",
    "                list_of_files_to_exclude.append(all_file_names_in_folder[n])\n",
    "            elif should_include == False & should_exclude == False:\n",
    "                serendip_files.append(all_file_names_in_folder[n])\n",
    "    \n",
    "    print('The number of files left after exclusions is {0}'.format(len(list_of_files_to_include)))\n",
    "    \n",
    "    return sorted(list_of_files_to_include), sorted(list_of_files_to_exclude), sorted(serendip_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Save The Rebinned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sarthak's function as modified by Liv Gaunt\n",
    "def exportToFits(rbflux, rbwave, rbivar, mask_name, file_names, incl_or_excl):\n",
    "\n",
    "    for i in range(len(rbflux)):\n",
    "            \n",
    "        hdu1 = fits.PrimaryHDU() #primary HDU (empty)\n",
    "        hdu1.header['INCLUDE'] = (incl_or_excl, 'Include in median calc if T') #this sets the tag for inclusion\n",
    "            \n",
    "        c1 = fits.Column(name='RBFLUX', array=rbflux[i], format='E')\n",
    "        c2 = fits.Column(name='RBWAVE', array=rbwave, format='E') #no [i] on rbwave since it's just one array\n",
    "        c3 = fits.Column(name='RBIVAR', array=rbivar[i], format='E')\n",
    "        hdu2 = fits.BinTableHDU.from_columns([c1, c2, c3]) #first extensional HDU (w data)\n",
    "            \n",
    "        hdul = fits.HDUList([hdu1, hdu2]) #combine both HDUs into file and write it below\n",
    "            \n",
    "        #this part puts the files to include in one folder, and those to exclude in another\n",
    "        if incl_or_excl == True:\n",
    "            hdul.writeto(path_name + '/SkySubData/{0}_Rebinned/{0}_Included'.format(mask_name) + '/' + 'rebinned_{0}'.format(file_names[i]))\n",
    "            \n",
    "        elif incl_or_excl == False:\n",
    "            hdul.writeto(path_name + '/SkySubData/{0}_Rebinned/{0}_Excluded'.format(mask_name) + '/' + 'rebinned_{0}'.format(file_names[i]))\n",
    "                \n",
    "        else:\n",
    "            hdul.writeto(path_name + '/SkySubData/{0}_Rebinned/{0}_Serendip'.format(mask_name) + '/' + 'rebinned_{0}'.format(file_names[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Save The Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportToFitsMedian(median,mask_name):\n",
    "    \n",
    "    hdu1 = fits.PrimaryHDU()\n",
    "        \n",
    "    c1 = fits.Column(name='MEDIAN',array=median,format=\"E\")\n",
    "    hdu2 = fits.BinTableHDU.from_columns([c1])\n",
    "        \n",
    "    hdul = fits.HDUList([hdu1,hdu2])\n",
    "        \n",
    "    hdul.writeto(path_name + '/SkySubData/{0}_Median/Median_of_{0}.fits.gz'.format(mask_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median Airglow Subtraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_subtraction(slit_index,rebinned_flux):\n",
    "    \n",
    "    new_flux = []\n",
    "    \n",
    "    spectrum = rebinned_flux[slit_index]\n",
    "   \n",
    "    for i in range(len(spectrum)):\n",
    "        if np.isfinite(spectrum[i]) == True:\n",
    "            new_flux.append(spectrum[i] - median[i])\n",
    "        else:\n",
    "            new_flux.append(spectrum[i])\n",
    "            \n",
    "    return new_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slit_nums(files):\n",
    "    \n",
    "    slit_nums = []\n",
    "    \n",
    "    if len(files) > 1:\n",
    "    \n",
    "        for i in range(len(files)):\n",
    "            parts_of_file_name = files[i].split(\".\")\n",
    "            slit_num = parts_of_file_name[2]\n",
    "            slit_nums.append(int(slit_num))\n",
    "            \n",
    "    return slit_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_slit_index(slit_nums,slit_num): \n",
    "    return slit_nums.index(slit_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportToFitsSkySub(mask_name,slit_nums,rebinned_flux,incl_or_excl):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mask_name : str, required\n",
    "        Name of mask.\n",
    "    slit_nums : list, required\n",
    "        List of slit number. Use slit_nums for 'include' slits or \n",
    "        slit_nums_exclude for 'exclude' slits.\n",
    "    rebinned_flux : list, required\n",
    "        A list containing arrays of rebinned flux. \n",
    "        Use rbflux for 'include' slits or rbflux_exclude \n",
    "        for 'excluded' slits.\n",
    "    incl_or_excl: bool, required\n",
    "        Use True for 'include' slits or False for 'exclude' slits.\n",
    "        \n",
    "\n",
    "    '''\n",
    "    \n",
    "    if incl_or_excl == True:\n",
    "        \n",
    "        for slit in slit_nums:\n",
    "            index = find_slit_index(slit_nums,slit)\n",
    "            skysub_spectrum = median_subtraction(index,rebinned_flux)\n",
    "            \n",
    "            \n",
    "            hdu1 = fits.PrimaryHDU()\n",
    "            c1 = fits.Column(name=\"SKYSUB_SPECTRUM\",array=skysub_spectrum,format=\"E\")\n",
    "            hdu2 = fits.BinTableHDU.from_columns([c1])\n",
    "            hdul = fits.HDUList([hdu1,hdu2])\n",
    "            hdul.writeto(path_name + \"/SkySubData/{0}_SkySub_Spectrum/{0}_Included/Slit_{1}_SkySub_Spectrum.fits.gz\".format(mask_name,slit))\n",
    "            \n",
    "        \n",
    "    elif incl_or_excl == False:\n",
    "        \n",
    "        for slit in slit_nums:\n",
    "            index = find_slit_index(slit_nums,slit)\n",
    "            skysub_spectrum = median_subtraction(index,rebinned_flux)\n",
    "            \n",
    "            \n",
    "            hdu1 = fits.PrimaryHDU()\n",
    "            c1 = fits.Column(name=\"SKYSUB_SPECTRUM\",array=skysub_spectrum,format=\"E\")\n",
    "            hdu2 = fits.BinTableHDU.from_columns([c1])\n",
    "            hdul = fits.HDUList([hdu1,hdu2])\n",
    "            hdul.writeto(path_name + \"/SkySubData/{0}_SkySub_Spectrum/{0}_Excluded/Slit_{1}_SkySub_Spectrum.fits.gz\".format(mask_name,slit))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define The Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_name = \"M33D2A\" #change to fit the appropriate mask "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define The Grating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grating = 600 #change between 600 and 1200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Files We Want to Include and Exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering files\n",
    "list_of_files_to_include, list_of_files_to_exclude, list_of_serendip_files = get_files_to_include(mask_name)\n",
    "\n",
    "#sorted\n",
    "#file_names = all slits used to create the median (airglow)\n",
    "#file_names_exclude = all slits that contain ISM emission lines \n",
    "#file_names_serendip = all serendip files\n",
    "#file_names_all = all slits excluding \"serendip\"\n",
    "\n",
    "file_names = list_of_files_to_include\n",
    "file_names_exclude = list_of_files_to_exclude\n",
    "file_names_serendip = list_of_serendip_files\n",
    "file_names_all = list_of_files_to_include + list_of_files_to_exclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting The Wavelength, Flux, and Inverse Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to comment out the codes in this section after you have rebinned and saved your data!!!\n",
    "\n",
    "Then make sure to uncomment them whenever you're working with a new mask and want to rebin!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting data\n",
    "#try getting and rebinning all files\n",
    "flux, wave, ivar = get_original_data(file_names, mask_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rebinning the original data\n",
    "rbflux, rbwave, rbivar = rebin(flux, wave, ivar, grating) # this takes about 4 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all excluded data\n",
    "flux_exclude, wave_exclude, ivar_exclude = get_original_data(file_names_exclude, mask_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rebinning the excluded data\n",
    "rbflux_exclude, rbwave_exclude, rbivar_exclude = rebin(flux_exclude, wave_exclude, ivar_exclude, grating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all serendip data \n",
    "#NOTE: we will never use it but is good to just process it\n",
    "flux_serendip, wave_serendip, ivar_serendip = get_original_data(list_of_serendip_files, mask_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rebinning the serendip da\n",
    "rbflux_serendip, rbwave_serendip, rbivar_serendip = rebin(flux_serendip, wave_serendip, ivar_serendip, grating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [#make three folders to store the rebinned data, the median, and the spectra\n",
    "        \"./SkySubData/{0}_Rebinned\".format(mask_name),\n",
    "        \"./SkySubData/{0}_Median\".format(mask_name),\n",
    "        \"./SkySubData/{0}_SkySub_Spectrum\".format(mask_name),\n",
    "    \n",
    "\n",
    "        #make sub-folders for rebinned data\n",
    "        \"./SkySubData/{0}_Rebinned/{0}_Excluded\".format(mask_name),\n",
    "        \"./SkySubData/{0}_Rebinned/{0}_Included\".format(mask_name),\n",
    "        \"./SkySubData/{0}_Rebinned/{0}_Serendip\".format(mask_name),\n",
    "        \"./SkySubData/{0}_SkySub_Spectrum/{0}_Excluded\".format(mask_name),\n",
    "        \"./SkySubData/{0}_SkySub_Spectrum/{0}_Included\".format(mask_name)]\n",
    "      \n",
    "for path in paths:\n",
    "    try: \n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path):\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Rebin Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exportToFits(rbflux, rbwave, rbivar, mask_name, file_names, True) \n",
    "exportToFits(rbflux_exclude, rbwave_exclude, rbivar_exclude, mask_name, file_names_exclude, False)\n",
    "exportToFits(rbflux_serendip, rbwave_serendip, rbivar_serendip, mask_name, file_names_serendip, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding The Median "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking the median\n",
    "median = find_median(rbflux) #median length is 10770 (M33D2A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Median As FITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportToFitsMedian(median,mask_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slits to Include and Exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slit_nums = get_slit_nums(file_names)\n",
    "slit_nums_exclude = get_slit_nums(file_names_exclude)\n",
    "\n",
    "all_slit_nums = get_slit_nums(file_names_all)\n",
    "\n",
    "print(\"Slit # to INCLUDE in median calculation: {0}\".format(slit_nums))\n",
    "print(\"Slit # to EXCLUDE: {0}\".format(slit_nums_exclude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Airglow Subtraction and Save Spectrum as FITS File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportToFitsSkySub(mask_name,slit_nums,rbflux,True) #saving 'included' sloits as FITS files\n",
    "exportToFitsSkySub(mask_name,slit_nums_exclude,rbflux_exclude,False) #saving 'excluded' slits as FITS files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import median_filter\n",
    "\n",
    "def moving_median(a, size=325):\n",
    "    \n",
    "    '''\n",
    "    Returns the moving median values of the array,\n",
    "    using a window of a given size, centered at\n",
    "    each point.\n",
    "    \n",
    "    Version - 4.0\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    a : ndarray\n",
    "        One dimensional flux array.\n",
    "    window : int, optional\n",
    "        The size of each segment for taking the median.\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    median_arr : One dimensional array of moving median.\n",
    "    \n",
    "    '''\n",
    "        \n",
    "    all_indices = np.arange(len(a))\n",
    "    finite_bool = np.isfinite(a)\n",
    "    nan_indices = all_indices[np.invert(finite_bool)]\n",
    "    nan_indices_set = set(nan_indices)\n",
    "    n = len(finite_bool)\n",
    "\n",
    "    if (nan_indices_set=={0,n} or nan_indices_set=={0} or nan_indices_set=={n}):\n",
    "        \n",
    "        finite_indices = all_indices[finite_bool]\n",
    "        nearest_finite_indices = np.searchsorted(finite_indices, nan_indices)\n",
    "        nearest_finite_indices = nearest_finite_indices - (nearest_finite_indices==len(finite_indices))\n",
    "        a[nan_indices] = a[finite_indices[nearest_finite_indices]][:]\n",
    "        median_arr = median_filter(a, size, mode='nearest')\n",
    "\n",
    "    elif (len(nan_indices_set)==0):\n",
    "        \n",
    "        median_arr = np.nan*np.ones(len(a))\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if True not in finite_bool:\n",
    "            median_arr = np.nan*np.ones(len(a))\n",
    "            \n",
    "        else:\n",
    "            finite_indices = all_indices[finite_bool]\n",
    "            nearest_finite_indices = np.searchsorted(finite_indices, nan_indices)\n",
    "            gap_indices = ((nearest_finite_indices>0) & (nearest_finite_indices<len(finite_indices)))\n",
    "            middle_nan_indices = nan_indices[gap_indices]\n",
    "            right_nearest_indices = finite_indices[nearest_finite_indices[gap_indices]]\n",
    "            left_nearest_indices = finite_indices[nearest_finite_indices[gap_indices] - 1]\n",
    "            right_distances = abs(right_nearest_indices - middle_nan_indices)\n",
    "            left_distances = abs(left_nearest_indices - middle_nan_indices)\n",
    "            right_is_near_bool = (left_distances > right_distances)\n",
    "            left_is_near_bool = (left_distances <= right_distances)\n",
    "            a[middle_nan_indices[right_is_near_bool]] = a[right_nearest_indices[right_is_near_bool]][:]\n",
    "            a[middle_nan_indices[left_is_near_bool]] = a[left_nearest_indices[left_is_near_bool]][:]\n",
    "            a[nan_indices[nearest_finite_indices==0]] = a[finite_indices[0]]\n",
    "            a[nan_indices[nearest_finite_indices==len(finite_indices)]] = a[finite_indices[-1]]\n",
    "            median_arr = median_filter(a, size, mode='nearest')\n",
    "    \n",
    "    return (median_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FITS Files for Marz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportToFitsMarz(mask_name,slit_nums,grating,rebinned_flux,rebinned_ivar,median,min_wave,max_wave):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mask_name : str, required\n",
    "        Name of mask.\n",
    "    slit_nums : list, required\n",
    "        List of slit number. \n",
    "    grating: int, required\n",
    "        600 or 1200\n",
    "    rebinned_flux : list, required\n",
    "        A list containing arrays of rebinned flux. \n",
    "    rebinned_ivar: list, required\n",
    "        A list containing arrays of rebinned inverse \n",
    "        variance.\n",
    "    median: list, required\n",
    "        Median of all included slits. Sky background.\n",
    "    min_wave: float or int, required\n",
    "        Left limit of the wavelength cutout.\n",
    "    max_wave: float or int, required\n",
    "        Right limit of the wavelength cutout.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # GETTING 'WAVELENGTH' 2D ARRAY\n",
    "    if grating == 600:\n",
    "        wavelength_array = new_wave_600\n",
    "    elif grating == 1200:\n",
    "        wavelength_array = new_wave_1200\n",
    "        \n",
    "    wave_cutout_boolean = ((wavelength_array>=min_wave) & (wavelength_array<=max_wave))\n",
    "    \n",
    "    array2d_wavelength = [wavelength_array[wave_cutout_boolean]] * len(slit_nums) #duplicating same array by number of excluded slits\n",
    "    \n",
    "    \n",
    "    #GETING 'INTENSITY' 2D ARRAY\n",
    "    array2d_intensity = [] #empty list to stores rbflux \n",
    "    \n",
    "    for slit in slit_nums: #sky subtraction and moving to empty list\n",
    "        index = slit_nums.index(slit)\n",
    "        skysub_spectrum = rebinned_flux[index] - median\n",
    "#         skysub_spectrum = skysub_spectrum - moving_median(skysub_spectrum-median, size=325)\n",
    "        skysub_spectrum = skysub_spectrum - moving_median(skysub_spectrum, size=325)\n",
    "        array2d_intensity.append(np.array(skysub_spectrum)[wave_cutout_boolean])\n",
    "            \n",
    "    #GETTING 'VARIANCE' 2D ARRAY\n",
    "    array2d_variance = [] #empoty list to stores variance\n",
    "    for inv_var in rebinned_ivar: #getting var from ivar and moving to empty list\n",
    "        var_list = []\n",
    "        for value in inv_var:\n",
    "            if value == 0:\n",
    "                var_list.append(value)\n",
    "            else:\n",
    "                var_list.append(1/value)\n",
    "        array2d_variance.append(np.asarray(var_list)[wave_cutout_boolean])\n",
    "        \n",
    "    #GETTING 'SKY BACKGROUND' 2D ARRAY\n",
    "    array2d_sky = [np.array(median)[wave_cutout_boolean]] * len(slit_nums) #duplicating same array by number of excluded slits\n",
    "#     array2d_sky = [np.zeros(len(wavelength_array))[wave_cutout_boolean]] * len(slit_nums)\n",
    "    \n",
    "    #WRITE TO FITS\n",
    "    hdu0 = fits.PrimaryHDU()\n",
    "    hdu1 = fits.ImageHDU(data=array2d_intensity,name=\"INTENSITY\") #Image HDU containing intensity\n",
    "    hdu2 = fits.ImageHDU(data=array2d_variance,name=\"VARIANCE\") #Image HDU containing variance\n",
    "    hdu3 = fits.ImageHDU(data=array2d_sky,name=\"SKY\") #Image HDU containing sky background\n",
    "    hdu4 = fits.ImageHDU(data=array2d_wavelength,name=\"WAVELENGTH\") #Image HDU containing wavelength\n",
    "    c1 = fits.Column(name=\"NAME\",array = slit_nums,format=\"E\") \n",
    "    hdu5 = fits.BinTableHDU.from_columns([c1]) #BinTable HDU containing info about slits (ex. ID,Dec,RA...)\n",
    "    #BinTableHDU isn't needed for calculation. It is use to label slits.\n",
    "    hdul = fits.HDUList([hdu0,hdu1,hdu2,hdu3,hdu4,hdu5])\n",
    "    hdul.writeto(\"./SkySubData/{0}_Marz.fits\".format(mask_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportToFitsMarz(mask_name,slit_nums_exclude,grating,rbflux_exclude,rbivar_exclude,median,6500,6800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
